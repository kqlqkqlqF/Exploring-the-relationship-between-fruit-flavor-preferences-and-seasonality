---
title: "Modeling Price Change of Seasonal Fruits Flavored Food Products: A Predictive Analysis"
subtitle: "Trump's Narrow Victory Over Harris by Less Than One Percent of the Supporting Rate"
author: 
  - Yiyi Feng
thanks: "Code and data are available at: https://github.com/kqlqkqlqF/Insights-and-Predictions-for-the-U.S.-Election.git."
date: today
date-format: long
abstract: "This study presents a predictive model for the 2024 U.S. Presidential Election, focusing on the race between Donald Trump and Kamala Harris. Our model forecasts a narrow victory for Trump, estimating his average support at 44.51% compared to Harris's 43.86%, with leads of Trump in swing states. The analysis shows that state and recency are important for understanding voter support trends, reflecting the electoral system's winner-takes-all nature. This research allows electoral forecasting by demonstrating how localized support influences national outcomes and shows the need for improved polling methodologies."
format:
  pdf:
    toc: true
    number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

#### Preamble ####
# Purpose: Help constructing the "Predictive Modeling for Forecasting the 2024 US Presidential Election" paper

# Author: Bo Tang, Yiyi Feng, Mingjing Zhan
# Date: 1 November 2024
# Contact: qinghe.tang@mail.utoronto.ca, yiyi.feng@mail.utoronto.ca, mingjin.zhan@mail.utoronto.ca

####Workspace setup ####

library(dplyr)
library(tibble)
library(here)
library(modelsummary)
library(tidyverse)
library(arrow)
library(ggplot2)
library(janitor)
library(knitr)
library(kableExtra)
library(caret)
library(rstanarm)

model_data <- read_parquet(here::here("data/02-analysis_data/combined_model_data.parquet"))
rain_data <- read_parquet(here::here("data/02-analysis_data/average_rain_data.parquet"))

```


# Introduction

The upcoming U.S. Presidential Election marks an important point in the nation’s political landscape, shaped by public opinion, social and economic factors, and the complexities of the electoral process. With Kamala Harris and Donald Trump competing for the presidency, accurately predicting the outcome is increasingly important. Polls not only reflect voter opinion but also influence campaign strategies and media coverage. However, challenges like sampling biases, inconsistent methods, and the gap between the popular vote and the electoral vote emphasize the need for an improved forecasting model. This paper aims to develop a predictive framework that uses national polling data and examines state-level dynamics, especially in key swing states that often decide election results.

Our main focus is the probability of Donald Trump winning the 2024 U.S. presidential election, represented by voter support rates. To estimate support for both Trump and Harris, we developed linear models that account for factors such as candidate identity, poll recency, state, sample size, poll score, and poll quality, along with interactions among these variables. By identifying the optimal model, we aim to determine how these factors and their combinations influence expected support, providing insights into each candidate's chances across different regions and polling conditions. This approach models support rates rather than direct winning probabilities, allowing for a nuanced prediction that reflects variations by candidate, state, and recency.

Our model predicts that Donald Trump will win by a narrow margin, with an average support of 44.51% compared to Kamala Harris's 43.86%. Trump leads in six out of seven key swing states, suggesting that this localized support could enhance his overall chances despite only a slight national lead. Among the predictor variables analyzed, state and recency are the most significant indicators of support trends, reflecting the "winner-takes-all" nature of the U.S. electoral system and the increasing accuracy of polling data as Election Day approaches.

The remainder of this paper is structured as follows: [@sec-data] provides an overview of the dataset, details of the parameters, outcome and predictor variables, and the packages used during processing. [@sec-model] explains the modeling approach, and best model selection, justifying the choice of predictors and outlining the methods used to forecast support for Trump and Harris. [@sec-results] presents the findings, including a summary of the predicted support rate for Trump, a comparison of the predicted support rates for Trump and Harris, and a breakdown of their support rates in each state. In [@sec-discussion], we discuss the implications of these results, the limitations of our analysis, and potential avenues for future research. Additional methodological details and diagnostics are included in the appendix.



# Data {#sec-data}

## Overview

In this analysis, we used R [@citeR] to investigate canadian grocery price data. Our dataset, sourced from Jacob Filipp's project hammer [@hammer], provided the change of canadian grocery price from 8 vendors: Voila, T&T, Loblaws, No Frills, Metro, Galleria, Walmart and Save-On-Foods, from February 28, 2024 to November 26, 2024 (when this article was written). We examined factors that might influencing the price of seasonal fruits flavored food, including vendor, rain fall, month and category of the food.

Several R packages were vital for our data manipulation, modeling, and visualization efforts. The dplyr package provided efficient tools for data transformation and summarization [@dplyr], while modelsummary enhanced the presentation of model outputs in a clear and organized manner [@modelsummary]. kableExtra created customizable tables to improve our data presentation [@kableExtra]. Finally, testthat ensured the reliability of our analyses through code testing [@testthat]. Our workflow closely adhered to best practices, as outlined in [@tellingstories], enhancing the robustness of our predictive framework.
--------------------------------------

## Measurement
	

In this section, we describe the process of transforming the raw Canadian grocery price data into a structured dataset for analysis. Since this study focuses on price changes in foods with seasonal fruit flavors, we selected bananas and strawberries as representatives. Bananas were chosen for their popularity in winter, and strawberries for spring. Compared to other seasonal fruits like watermelon and pomegranate, bananas and strawberries have a larger consumer base in Canada, making it easier to collect relevant data for model building.

The original Canadian grocery price data was collected by Jacob Filipp through screen-scraping the website interfaces of eight vendors and compiled into the \textbf{Project Hammer} dataset. This dataset contains two tables: \textbf{Hammer 4 Raw} and \textbf{Hammer 4 Product}.
\textbf{Hammer 4 Raw} includes the scrape time, product name, single-item price, unit price (e.g., price per 100g), past prices, additional information (e.g., availability or discounts), and a unique product ID.
\textbf{Hammer 4 Product} provides detailed information, such as brand, vendor, sales unit, and product detail page links.
Since the data comes from website scraping, it contains many gaps and ambiguities, making cleaning difficult. Details about data collection and cleaning are provided in Appendix A.

To better analyze price changes for banana and strawberry-flavored foods, we added data from the \textbf{"About Rain Gauge Locations and Precipitation"} dataset from Open Data Toronto []. This dataset includes rain gauge locations across Toronto and recorded precipitation. Rainfall was included as a predictor since consumer demand for seasonal fruits often correlates with weather conditions, such as a preference for watermelon and strawberries during dry summers []. The dataset only uses rainfall data because the original grocery price data lacks sales location details.

This structured dataset enables us to analyze trends in seasonal fruit-flavored food prices over time. The goal is to examine price trends for these foods during in-season and off-season sales and identify key influencing factors.


## Outcome Variables

### Overview of Change of Monthly Averaged Price for Banana and Strawberry Flavored Product

[@fig-one] illustrates the distribution of approval ratings for Trump. The majority of the approval ratings fall between 40% and 55%, forming a shape that resembles a normal distribution, with a peak around the 45% to 50% range. This suggests that, within the analyzed sample, most of the approval ratings cluster in this middle range, with relatively few instances of extremely high or low ratings.

The lower frequency of approval ratings below 30% and above 60% indicates that these extremes are relatively uncommon in the dataset. Overall, the concentration of support in this central range suggests a fairly consistent level of public support for Trump.

```{r}
#| label: fig-one
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for average price distribution
ggplot(model_data, aes(x = monthly_avg_price)) +
  geom_histogram(aes(y = ..density..),
                 bins = 30,
                 fill = "blue",
                 color = "black",
                 alpha = 0.7
  ) +
  geom_density(color = "black", fill = "salmon", alpha = 0.6) +
  labs(
    x = "Average Price",
    y = "Density"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    strip.text = element_text(size = 12), # Adjust facet label size
    axis.title = element_text(size = 14), # Adjust axis title size
    axis.text = element_text(size = 12)  # Adjust axis label size
  )


```

```{r}
#| label: fig-two
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(model_data, aes(x = as.factor(month), y = price_change, color = price_change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )


```

## Predictor Variables

### Summary of Predictor Variables

- **Vendor:** The U.S. state where the poll was conducted, if applicable.

- **Average Rainfall Per Month:** A numeric rating from 2.0 to 3.0 indicates each pollster’s reliability.

- **Food Category:** The total number of respondents participating in the poll.

- **Month:** A quantitative measure of the pollster’s reliability, where lower values suggest higher predictive accuracy.

### Vendor

According to [@fig-state], we observe an interesting trend: in traditionally Republican states, Trump's support is not markedly high and is even relatively low in places like Oklahoma and Tennessee. Conversely, in states typically aligned with the Democratic Party, as well as in swing states, Trump’s support is unexpectedly higher. The "national" category in the chart represents data spanning the entire country without focusing on specific states, showing Trump’s national support nearing but not reaching 50%. This suggests Trump’s appeal may be crossing traditional partisan lines, gaining unexpected traction outside Republican strongholds. Overall, his estimated national support stands at around 45%.

```{r}
#| label: fig-vendor
#| fig-cap: Overview of the Percentage Support of Trump Across Different States
#| echo: false
#| warning: false
#| message: false

# Create a bar plot for vendor distribution
ggplot(model_data, aes(x = vendor)) +
  geom_bar(fill = "blue", color = "black", alpha = 0.7) + 
  labs(
    x = "Vendor",
    y = "Count",
    title = "Vendor Distribution"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels for better readability
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )


```

### Average Rainfall Per Month

In [@fig-rain], we analyzed the relationship between numeric grade and Trump’s support rate. Each point in the chart represents a poll, with its numeric grade on the x-axis and Trump’s support rate on the y-axis. The nearly flat trend line suggests that numeric grade has no clear relationship with Trump’s support rate. However, this is a basic analysis and does not rule out the possibility that numeric grade could impact Trump’s support rate under different variable conditions.

```{r}
#| label: fig-rain
#| fig-cap: Relationship between Numeric Grade and Support Percentage of Trump
#| echo: false
#| warning: false
#| message: false

# Assuming rain_data is your dataset
ggplot(rain_data, aes(x = as.factor(month), y = avg_rainfall)) +
  geom_bar(stat = "identity", fill = "blue", color = "black", alpha = 0.7) + 
  labs(
    x = "Month",
    y = "Average Rainfall (mm)",
    title = "Average Rainfall per Month"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )


```

### Food Category

In [@fig-sample-size], we examined the relationship between sample size and Trump’s support rate. The results show a slight downward trend in Trump’s support as the sample size increases. However, since most data points are concentrated in the 0–4000 range, with fewer data points above 4000, this may not accurately reflect the true relationship between sample size and support rate.

```{r}
#| label: fig-category
#| fig-cap: Relationship between Sample Size and Support Percentage for Trump
#| echo: false
#| warning: false
#| message: false
# Convert pct column to numeric if it is not already

# Create the plot for price distribution by category
ggplot(model_data, aes(x = category, y = monthly_avg_price, color = monthly_avg_price)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Category",
    y = "Average Price",
    title = "Average Price Distribution by Category"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )



```

### Month

Analysis of [@fig-two] shows no clear proportional or inverse relationship between poll scores and Trump’s support rate. This suggests that while a higher poll score may indicate greater reliability, it does not directly translate into changes in candidate support. This also supports the data's credibility, as Trump’s support rate remains consistent regardless of pollster ratings.

```{r}
#| label: fig-month
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(model_data, aes(x = as.factor(month), y = monthly_avg_price, color = monthly_avg_price)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price",
    title = "Average Price Distribution by Month"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )


```


# Model {#sec-model}

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

model_rf <-
  readRDS(file = here::here("models/model_rf.rds"))

model_linear_1 <-
  readRDS(file = here::here("models/model_linear_1.rds"))

model_linear_2 <-
  readRDS(file = here::here("models/model_linear_2.rds"))

model_linear_3 <-
  readRDS(file = here::here("models/model_linear_3.rds"))

model_linear_4 <-
  readRDS(file = here::here("models/model_linear_4.rds"))

model_linear_5 <-
  readRDS(file = here::here("models/model_linear_5.rds"))


```

The goal of this section is to address the inherent biases and variations present in polling data to build a robust predictive model. The key challenge lies in achieving an optimal balance between model complexity and fit, ensuring that the model accurately captures the dynamics of polling data while avoiding overfitting. To this end, we evaluated multiple model specifications to identify the one that best meets our forecasting objectives.

We chose to use "numeric grade" and "poll score" as variables instead of "pollster" because "pollster" tends to be highly subjective. People often select polling organizations that favor their preferred candidate, which can introduce bias. In contrast, "numeric grade" and "poll score" offer a more objective, quantified reflection of poll quality and bias, helping to improve accuracy and reliability in the regression analysis. Additionally, we focused on key factors such as sample size, state, and recency, gradually adding complexity to the model.

By systematically comparing model specifications that incorporate different variables, we aim to identify a model that strikes the right balance between predictive accuracy and generalizability, ultimately providing the reliable forecast results.

## Model Set-up

We aim to model the percentage of support for a candidate based on factors including Vendor, Category, state, sample size, poll score, and numeric grade. This model includes interaction terms to capture how combinations of these factors jointly impact the support percentage, providing a better understanding of the influences on candidate support.

\
\begin{align*}
\mathrm{Pct}_i = &\ \beta_0 + \beta_1 \cdot \mathrm{Vendor}_i + \beta_2 \cdot \mathrm{Category}_i + \beta_3 \cdot \mathrm{Month}_i + \beta_4 \cdot \mathrm{Average Rainfall}_i \\
& + \beta_5 \cdot (\mathrm{Vendor}_i \times \mathrm{Category}_i) + \beta_6 \cdot (\mathrm{Category}_i \times \mathrm{Month}_i) \\
& + \beta_7 \cdot (\mathrm{Month}_i \times \mathrm{Average Rainfall}_i) + \beta_8 \cdot (\mathrm{Category}_i \times \mathrm{Average Rainfall}_i) + \epsilon_i
\end{align*}
\

Where

-   $y_i$ : The percentage of support for candidate in poll i.
-   $\beta_0$: Intercept term, representing the predicted `Average price of the Product` when all independent variables are 0.
-   $\beta_1$: Main effect of `Vendor`, capturing the influence of the candidate.
-   $\beta_2$: Main effect of `Category`, reflecting the influence of how recent the poll is on `Average price of the Product`.
-   $\beta_3$: Main effect of `Month`, indicating the impact of different states on `Average price of the Product`.
-   $\beta_4$: Main effect of `Average Rainfall`, indicating the impact of different states on `Average price of the Product`.
-   $\beta_5$: Interaction effect between `Vendor` and `Category`, capturing the combined influence of the candidate and state.
-   $\beta_6$: Interaction effect between `Category` and `Month`, reflecting the joint impact of recency and state on `pct`.
-   $\beta_7$: Interaction effect between `Month` and `Average rainfall`, representing the combined influence of the candidate and recency of the poll.
-   $\beta_8$: Interaction effect between `Category` and `Average rainfall`, representing the combined influence of the candidate and recency of the poll.
-   $\epsilon_i$: The error term, assumed to follow a normal distribution with mean 0.

### Model Interpretation

This regression model is designed to predict voter support rates by incorporating factors and interaction terms. The model includes an intercept term, representing the baseline support rate when all other predictors are zero. Among the main effects, it includes terms for candidate identity, poll recency, and state, capturing the influence of these individual factors on support rate. For instance, candidate identity indicates how different candidates affect voter support, poll recency reflects how recent the poll is, and the state variable accounts for regional variations in support.

To capture more complex relationships, the model incorporates two-way interaction terms. These include interactions between candidate and recency, candidate and state, and recency and state. Each of these terms helps identify how one factor might alter the effect of another. For example, the interaction between candidate and recency shows how the influence of recency might differ for each candidate, while the interaction between candidate and state captures how support for different candidates varies by region. Additionally, the model includes a three-way interaction term among candidate identity, poll recency, and state, allowing it to account for combined effects that vary across candidates, states, and the timing of the poll.

The model also includes several other predictors, including sample size, poll score, and numeric grade. These predictors help account for variations in the data, with sample size ensuring that different poll sizes are properly weighted, poll score reflecting potential bias within each poll, and numeric grade indicating the reliability of each poll. Finally, the model includes an error term to capture any unexplained variation in support rate, adding robustness to its predictions. Overall, this structure allows the model to incorporate both straightforward and complex relationships, providing a reliable prediction of voter support.

## Model Justification

```{r}
#| label: tbl-linear
#| tbl-cap: "Predicted Average Supporting Percentages for Donald Trump vs. Kamala Harris by Random Forest"
#| echo: false
#| warning: false
#| message: false

# Extract summary statistics and add variables included in each model
model_summary <- tibble(
  Model = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),
  Variables = c(
    linebreak("Vendor, Category, Month, Average Rainfall"), 
    linebreak("Vendor, Category × Month, Average Rainfall"), 
    linebreak("Vendor, Category, Month × Average Rainfall"),
    linebreak("Vendor, Month, Category × Average Rainfall"),
    linebreak("Vendor × Category, Month, Average Rainfall")
  ),
  `R²` = round(c(summary(model_linear_1)$r.squared, 
                 summary(model_linear_2)$r.squared, 
                 summary(model_linear_3)$r.squared,
                 summary(model_linear_4)$r.squared,
                 summary(model_linear_5)$r.squared), 5),
  `Adjusted R²` = round(c(summary(model_linear_1)$adj.r.squared,
                          summary(model_linear_2)$adj.r.squared, 
                          summary(model_linear_3)$adj.r.squared,
                          summary(model_linear_4)$adj.r.squared,
                          summary(model_linear_5)$adj.r.squared), 5),
  `AIC` = round(c(AIC(model_linear_1), AIC(model_linear_2), AIC(model_linear_3), AIC(model_linear_4), AIC(model_linear_5)), 5),
  `BIC` = round(c(BIC(model_linear_1), BIC(model_linear_2), BIC(model_linear_3), BIC(model_linear_4), BIC(model_linear_5)), 5),
  `RMSE` = round(c(sqrt(mean(residuals(model_linear_1)^2)), 
                   sqrt(mean(residuals(model_linear_2)^2)), 
                   sqrt(mean(residuals(model_linear_3)^2)),
                   sqrt(mean(residuals(model_linear_4)^2)),
                   sqrt(mean(residuals(model_linear_5)^2))), 5)
)

# Display the table using kable
model_summary %>%
  kable(digits = 5, escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(2, width = "8em")


```



[@tbl-model-compare] summarizes the performance metrics for five models, each with progressively more variables and interactions.

Model 1, which includes only basic predictors (Sample Size, Poll Score, Numeric Grade, and State), shows limited explanatory power, with an R² of 0.0526 and a high RMSE of 5.39274, indicating poor predictive accuracy. Adding Category in Model 2 slightly improves performance, increasing R² to 0.09461, but the RMSE remains high at 5.27184, suggesting only minor gains in prediction accuracy. Model 3 further incorporates Vendor, leading to a modest increase in R² to 0.09644, yet with minimal impact on RMSE (5.26649), indicating limited additional explanatory value from this variable alone.

The inclusion of an interaction between Vendor and State in Model 4 significantly enhances the model’s fit, raising R² to 0.46417 and reducing RMSE to 4.05562. This improvement suggests that state-specific variations in candidate popularity are important for predictive accuracy. Finally, Model 5 builds upon Model 4 by adding a three-way interaction among Vendor, State, and Category. This final model achieves the highest R² (0.48581) and the lowest RMSE (3.97288), indicating the best fit and prediction accuracy across all models.

In conclusion, Model 5 is chosen as it captures complex interactions and provides the best balance of explanatory power and prediction accuracy, as evidenced by its highest R² and lowest RMSE.

## Optimization

```{r}
#| label: tbl-rfsum
#| tbl-cap: Model Summary with Included Variables and Interactions
#| echo: false
#| warning: false
#| message: false

# Extract OOB error
oob_error <- model_rf$mse[model_rf$ntree]

# Number of trees
num_trees <- model_rf$ntree

# Extract variable importance
var_importance <- importance(model_rf)
importance_table <- as_tibble(var_importance, rownames = "Variable") %>%
  rename(
    `%IncMSE` = `%IncMSE`,
    `IncNodePurity` = `IncNodePurity`
  )

# Construct a summary table for model metrics
model_metrics <- tibble(
  Metric = c("Number of Trees", "Out-of-Bag Error (MSE)"),
  Value = c(num_trees, round(oob_error, 5))
)

# Display model metrics table
model_metrics %>%
  kable(digits = 5, escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" " = 1, "Random Forest Model Metrics" = 1)) %>%
  column_spec(1, bold = TRUE, width = "12em")

# Display variable importance table
importance_table %>%
  mutate(
    `%IncMSE` = round(`%IncMSE`, 2),
    `IncNodePurity` = round(`IncNodePurity`, 2)
  ) %>%
  kable(digits = 2, escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" " = 1, "Variable Importance in Random Forest" = 2)) %>%
  column_spec(1, bold = TRUE, width = "12em")


```

Since we identified the limitations of linear models in handling interaction terms during our research, if we wish to investigate this issue further, we propose an optimized model—Random Forest. The reason we chose Random Forest over a linear model is because our data includes interaction terms. Random Forest excels at handling interactions and nonlinear relationships, as it can automatically identify and leverage these complex interactions through its decision tree structure, without requiring manual adjustments to the model structure. In contrast, linear models have limited capabilities for handling interactions, typically requiring manual specification and hard to capture nonlinear effects. Given that our data contains multiple interactions, Random Forest can more flexibly adapt to the data structure, improving prediction accuracy and model stability.

[@tbl-rfsum] demonstrates the prediction results obtained through Random Forest. Compared to a linear model, this result may be more accurate; however, in the overall study, our main focus is the linear model.


# Result {#sec-results}

```{r}
#| label: tbl-trump
#| tbl-cap: "Summary Statistics of Predicted Support for Donald Trump"
#| message: false
#| echo: false
#| warning: false

# Step 1: Predict price changes for the existing dataset
predict_data_lm <- model_data %>%
  mutate(Predicted_Price_Change = predict(model_linear_2, newdata = model_data))

# Step 2: Filter the dataset for 'strawberry' and 'banana' flavor products
flavor_data <- predict_data_lm %>%
  filter(flavor %in% c("strawberry", "banana"))

# Step 3: Calculate average predicted price change for each flavor across the dataset
flavor_summary <- flavor_data %>%
  group_by(flavor) %>%
  summarise(
    Avg_Price_Change = mean(Predicted_Price_Change, na.rm = TRUE),
    Median_Price_Change = median(Predicted_Price_Change, na.rm = TRUE),
    Min_Price_Change = min(Predicted_Price_Change, na.rm = TRUE),
    Max_Price_Change = max(Predicted_Price_Change, na.rm = TRUE),
    SD_Price_Change = sd(Predicted_Price_Change, na.rm = TRUE),
    Total_Products = n()
  )

# Step 4: Present the summary using kable
flavor_summary %>%
  kable(
    col.names = c("Flavor", "Avg Change", "Median Change", "Min Change", "Max Change", "SD of Change", "Total Products"),
    digits = 3,
    booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"))



```

[@tbl-trump] shows the statistical information of the predicted support rate for Trump. The average support rate is 44.51%, with a median of 44.44%. The support rate ranges from a minimum of 28% to a maximum of 67.6%. The standard deviation of the support rate is 3.98, indicating some variability in the predictions. The data is derived from 2248 polls.

```{r}
#| label: fig-lmone
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(predict_data_lm, aes(x = as.factor(month), y = Predicted_Price_Change, color = Predicted_Price_Change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price",
    title = "Average Price Distribution by Month"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  ) 

```

[@tbl-modelresults] presents the model's average predicted supporting percentages for Donald Trump and Kamala Harris, along with their normalized percentages. According to the model's predictions, Donald Trump's average predicted supporting percentage is 44.51%, while Kamala Harris's is 43.86%. The normalized percentages adjust these predicted values to relative proportions, with Donald Trump at 50.37% and Kamala Harris at 49.63%. These results show that although Donald Trump's average predicted supporting percentage is slightly higher than Kamala Harris's, the support rates for both candidates are nearly equal, with Donald Trump holding a slight edge.

```{r}
#| label: fig-lmtwo
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(predict_data_lm, aes(x = category, y = Predicted_Price_Change, color = Predicted_Price_Change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price",
    title = "Average Price Distribution by Month"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels
  )

```



```{r}
#| label: fig-rfone
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

predict_data_rf <- model_data %>%
  mutate(predicted_price_change = predict(model_rf, newdata = model_data))

# Create the plot for price distribution by month
ggplot(predict_data_rf, aes(x = as.factor(month), y = predicted_price_change, color = predicted_price_change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price",
    title = "Average Price Distribution by Month"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )


```

[@fig-map] shows the predicted winner by state. Red indicates Trump’s predicted lead, blue indicates Harris’s lead, and gray marks states with insufficient data to predict the winner. This map visually represents regional support patterns for both candidates across the country. Trump shows strength in parts of the Midwest and South, while Harris performs better in parts of the Northeast and West. The table below [@tbl-model-state] presents the specific support rate figures.

```{r}
#| label: fig-rftwo
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

predict_data_rf <- model_data %>%
  mutate(predicted_price_change = predict(model_rf, newdata = model_data))

# Create the plot for price distribution by month
ggplot(predict_data_rf, aes(x = category, y = predicted_price_change, color = predicted_price_change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price",
    title = "Average Price Distribution by Month"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels
  )


```

[@tbl-model-state] provides detailed data for each state’s predicted support rate and expected winner. Together with [@fig-map], it offers a better understanding of Trump and Harris’s support levels in each state.

# Discussion {#sec-discussion}

## Summery of Findings

Our model predicts a narrow victory for Donald Trump, with an average support of 44.51% compared to Kamala Harris’s 43.86%. This result aligns with the predictions from our Random Forest model in [@tbl-rf], which also suggests a slight edge for Trump. However, since a higher popular vote does not guarantee an election win, and both models indicate no significant lead, we hesitate to conclude that Trump is highly likely to win.

Looking at support across states, Trump has a clear advantage in the swing states, which strengthens his position in our prediction. Out of seven swing states: Wisconsin, Pennsylvania, North Carolina, Nevada, Michigan, Georgia, and Arizona [@swing], Trump leads six. Since swing states play an important role in the election outcome, we believe that even with a slight national lead, Trump’s support in these states could give him an advantage over Harris.

Among all predictor variables, state and the recency of poll data stand out as the most effective indicators of support trends. This finding aligns with structural aspects of the U.S. election system: most states use a “winner-takes-all” approach, where winning the majority yields all electoral votes, and many states have strong historical party preferences. Consequently, state-level support has a direct impact on the election outcome. Additionally, as Election Day nears, polling data becomes increasingly accurate, better reflecting actual voter intentions.

## Limitation

Our analysis focuses exclusively on data related to Trump, which may weaken the overall analysis. In organizing the data, we excluded poll data with low numeric grades to enhance its credibility; however, this approach resulted in a smaller sample size and reduced coverage. When examining the relationship between state and supporting percentage (PCT), we did not integrate PCT with sample size for comparison. We believe that all decisions made by the collective data should be treated equally, regardless of sample size. This perspective has led to some counterintuitive results, such as states where Trump’s party is strong giving him fewer votes. Additionally, a significant portion of our raw data lacks exact state labels, which introduces errors in analyzing the relationship between state and PCT, even after processing.

Choosing a linear regression model to predict election results has several clear drawbacks. First, linear regression assumes a linear relationship between variables, which often does not hold in reality. Additionally, linear models have limitations when handling multiple interaction terms. In our model, we selected a three-way interaction term by combining Vendors, Category, and State. This increases the complexity of the model, but linear regression struggles to automatically adapt to and capture these complex interactions, potentially leading to less accurate predictions.
Furthermore, linear regression is sensitive to outliers and noise in the data, making the model susceptible to instability due to these factors. It is also vulnerable to multicollinearity; for instance, Numeric Grade and Poll Score may have high correlations, which can make the model coefficients unreliable. This sensitivity and reliance on linear assumptions reduce the model’s ability to accurately predict complex, nonlinear relationships in the data.

## Future Study

In future research, if we continue to use a linear regression model to study U.S. election outcomes, we will focus on enhancing the model’s stability and generalization ability. We may consider using Lasso regression to reduce overfitting and address issues with model accuracy, ensuring that our model performs better when handling different or more complex datasets. Additionally, to prepare for the next election, we may introduce more data parameters and sources to improve the accuracy and applicability of election predictions, helping to decrease biases and false data caused by subjective factors. For example, we could incorporate demographic data, regional economic data, and social sentiment analysis to add parameters that reduce subjective influence, providing the model with a new perspective to analyze how different economic and cultural factors affect presidential choice across regions. 

Moreover, by analyzing voter characteristics, we could address the instability of swing state data by building a profile of swing state voters and their characteristics to better predict the outcome in these states. If linear regression proves insufficient, we may consider more complex models, such as Random Forests or Neural Networks, to better capture nonlinear relationships and complex interactions among variables. Ultimately, this approach could lead to a more accurate election prediction model.


\newpage

# Appendix a. {-}

## Overview of Emerson College Polling Methodology (October 23-25, 2024)

The Emerson College Polling conducted a survey from October 23 to 25, 2024, targeting 1,000 likely voters to investigate the differences in support for various candidates. In this presidential election, 58% support former President Donald Trump, while 39% support Vice President Kamala Harris.

## Population, Frame, and Sample

In this context, the target population consists of likely voters in the U.S. elections, defined by their likelihood to vote in the upcoming elections and their voting history, both of which are self-reported in the survey. The sampling frame specifically focuses on likely voters in Montana, who were reached through a combination of cell phone contacts provided by Aristotle and an online voter panel from CINT. The sample consists of 1,000 likely voters randomly selected from the sampling frame, with their status determined by a combination of voter history, registration status, and demographic data, all of which are self-reported. This methodology provides a balanced overview of Montana voters' priorities, with a credibility interval of +/- 3%.

## Sampling Approach and Trade-offs

Emerson College utilized a mixed-mode sampling approach for its poll of likely voters in Montana. This strategy involved two main methods: sending MMS text messages linked to an online survey using Aristotle’s voter lists and accessing a pre-screened, opt-in online panel from CINT. The MMS method is efficient and cost-effective, allowing participants to complete the survey at their convenience, which can enhance response rates. The online panel broadens coverage to include voters not reachable through text, capturing a wider demographic range across the state. Together, these methods create a diverse sample while reducing costs compared to traditional phone or in-person interviews.

However, this approach has trade-offs. The MMS survey requires recipients to have active cell phones and internet, potentially excluding older or less tech-savvy voters. Additionally, the online panel consists of self-selected participants, which may not fully reflect the general voter population. Mixing data from both sources can introduce inconsistencies, as each method may attract different respondent types, necessitating careful weighting to maintain balance and accuracy. Smaller demographic subsets, such as age, race, or education, carry higher credibility intervals due to reduced sample sizes, limiting precision in analysis. Overall, the mixed approach optimizes reach, reduces costs, and shows the priority needs of Montana’s voters, although there are limitations.

## Non-response Handling

Emerson College does not provide specific details regarding its non-response management. While it mentions that data were weighted by demographics such as gender, education, race, age, party registration, and region to align with the 2024 likely voter model, this weighting primarily addresses demographic imbalances and does not directly mitigate non-response bias. The survey lacks information on common non-response strategies, such as follow-up attempts, participation incentives, or specific adjustments for non-responders. This absence raises concerns about potential non-response bias, particularly if certain demographic groups were less likely to engage with the survey.

## Questionnaire Design

This questionnaire has strong points. Its straightforward and clear wording makes questions easy for respondents to follow and reduces potential confusion. By focusing on issues like the economy, housing, and voter approval for specific candidates, it captures key voter concerns in Montana, offering a concise view. The use of multiple questions around candidate approval, voter issues, and demographics adds depth to the questionnaire.
However, the questionnaire also has limitations. While demographic questions enhance the survey’s representativeness, smaller groups (e.g., nonbinary individuals) may carry higher credibility intervals, reducing precision for those subgroups. The mixed-mode approach (online panel and mobile) improves access but still risks non-response bias, as certain demographics might be less likely to participate. Overall, the design achieves clarity and breadth, though response biases and sample variations should be considered in interpreting the findings. For example, in this survey of 1,000 Montana voters, only 5 respondents identified as nonbinary or other genders. Since statistical reliability depends on the number of responses, small groups have higher variability, meaning their responses can swing widely due to each individual answer carrying greater weight.

# Appendix b. {-}

## Idealized Methodology for Forecasting the U.S. Presidential Election

We aim to develop a methodology for forecasting U.S. presidential election outcomes by conducting a survey with a $100,000 budget. Using stratified random sampling and multi-mode recruitment, the survey targets 10,000 likely voters across demographic and regional lines. Key measures include data validation checks, weighted analysis, and predictive modeling to ensure accuracy. Results will be enriched by aggregating reputable data sources like FiveThirtyEight for a better forecast.

## Budget Allocation

Funding allocations will focus on ensuring thorough and effective sampling, recruitment, data validation, and analysis methods are employed with a total budget of no more than $10,000. The proposed budget breakdown is as follows:

Survey platform costs: $10,000 (subscription fees for online survey tools such as Google Forms or Qualtrics)

Respondent incentives: $10,000 (gift cards or other incentives to encourage participation)

Recruitment and staffing: $35,000 (staffing costs for survey distribution and data collection)

Data analysis tools: $20,000 (statistical software licenses, data cleaning and analysis)

Marketing and promotion: $10,000 (awareness and engagement campaigns)

Contingency fund: $5,000 (for unexpected expenses)

## Sampling Approach

The sampling approach will employ a stratified random sampling method to ensure representation across various demographic groups, including age, gender, race, education level, geographical location, and party affiliation. The target population consists of likely voters in the U.S., defined by historical voting behavior and self-reported intentions to vote. A sample size of approximately 10,000 respondents will be aimed at ensuring statistical robustness and a credibility interval of +/- 1% at a 95% confidence level.
This will be achieved through a combination of national voter registration databases to identify potential respondents. For example, we can utilize the National Voter Registration Act (NVRA) data from the National Association of Secretaries of State (NASS) to access information on registered voters. This database will allow us to filter for likely voters based on their registration status and historical voting behavior, ensuring that our sampling frame is representative of the electorate. By using reliable sources, we can create a sampling framework that enhances the accuracy of our election forecasts.

## Respondent Recruitment and Data Validation

To reach the target population, a multi-mode recruitment strategy will be implemented:
Online Surveys: Use Google Forms to distribute the survey electronically.
Telephone Surveys: Conduct live telephone interviews to capture demographics that might not engage online.
Text Messaging Surveys: Implement SMS surveys to reach younger demographics and those without regular internet access.
Incentives: Offer gift cards or other small incentives for participation, particularly for online respondents. This can enhance response rates and engagement.

To effectively reach our target population and capture a diverse range of perspectives, we will implement a multi-mode recruitment strategy tailored to different demographic groups and communication preferences. This approach includes online surveys using a Google Forms questionnaire, which will be widely distributed through social media, email lists, and community networks to maximize reach among individuals who frequently engage online. The user-friendly platform allows participants to complete the survey quickly and anonymously on any internet-enabled device. The survey can be accessed through the following link: [https://forms.gle/oSbad52Vuw9Z9Wf46](https://forms.gle/oSbad52Vuw9Z9Wf46). Additionally, we will conduct live telephone interviews to include participants who may not be reachable through online channels, ensuring we capture responses from populations that might otherwise be underrepresented. To further engage younger demographics and individuals with limited internet access, we will implement SMS-based surveys, allowing participants to respond quickly via text. To encourage participation and improve response rates, small incentives such as digital gift cards will be offered, particularly for online respondents, with details communicated at the survey's start and awarded upon completion to ensure transparency. This comprehensive approach will enable us to gather a robust and representative dataset, providing valuable insights into the preferences and priorities of voters across multiple demographics.

## Poll Aggregation and Modeling

Poll results will be aggregated using statistical methods to identify trends and analyze historical voting patterns. For model building, we will implement a weighted analysis to ensure demographic representation, applying specific weights based on factors such as age, gender, race, and education level, as well as state significance to reflect regional variations in voter behavior. Predictive analytics will primarily involve logistic regression to model voting preferences and forecast election outcomes, supplemented by time-series analysis to track changes in voter sentiment over the campaign period. To enhance our findings, we will combine our data with reputable sources like FiveThirtyEight, utilizing their aggregation techniques to enrich our analysis. 

\newpage

# References

