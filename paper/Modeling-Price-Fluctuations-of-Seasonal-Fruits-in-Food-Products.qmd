---
title: "Modeling Price Change of Seasonal Fruits Flavored Food Products: A Predictive Analysis"
subtitle: "Trump's Narrow Victory Over Harris by Less Than One Percent of the Supporting Rate"
author: 
  - Yiyi Feng
thanks: "Code and data are available at: https://github.com/kqlqkqlqF/Insights-and-Predictions-for-the-U.S.-Election.git."
date: today
date-format: long
abstract: "This study presents a predictive model for the 2024 U.S. Presidential Election, focusing on the race between Donald Trump and Kamala Harris. Our model forecasts a narrow victory for Trump, estimating his average support at 44.51% compared to Harris's 43.86%, with leads of Trump in swing states. The analysis shows that state and recency are important for understanding voter support trends, reflecting the electoral system's winner-takes-all nature. This research allows electoral forecasting by demonstrating how localized support influences national outcomes and shows the need for improved polling methodologies."
format:
  pdf:
    toc: true
    number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

#### Preamble ####
# Purpose: Help constructing the "Predictive Modeling for Forecasting the 2024 US Presidential Election" paper

# Author: Bo Tang, Yiyi Feng, Mingjing Zhan
# Date: 1 November 2024
# Contact: qinghe.tang@mail.utoronto.ca, yiyi.feng@mail.utoronto.ca, mingjin.zhan@mail.utoronto.ca

####Workspace setup ####

library(dplyr)
library(tibble)
library(here)
library(modelsummary)
library(tidyverse)
library(arrow)
library(ggplot2)
library(janitor)
library(knitr)
library(kableExtra)
library(caret)
library(randomForest)
library(rstanarm)

model_data <- read_parquet(here::here("data/02-analysis_data/combined_model_data.parquet"))
rain_data <- read_parquet(here::here("data/02-analysis_data/average_rain_data.parquet"))

```


# Introduction

The upcoming U.S. Presidential Election marks an important point in the nation’s political landscape, shaped by public opinion, social and economic factors, and the complexities of the electoral process. With Kamala Harris and Donald Trump competing for the presidency, accurately predicting the outcome is increasingly important. Polls not only reflect voter opinion but also influence campaign strategies and media coverage. However, challenges like sampling biases, inconsistent methods, and the gap between the popular vote and the electoral vote emphasize the need for an improved forecasting model. This paper aims to develop a predictive framework that uses national polling data and examines state-level dynamics, especially in key swing states that often decide election results.

Our main focus is the probability of Donald Trump winning the 2024 U.S. presidential election, represented by voter support rates. To estimate support for both Trump and Harris, we developed linear models that account for factors such as candidate identity, poll recency, state, sample size, poll score, and poll quality, along with interactions among these variables. By identifying the optimal model, we aim to determine how these factors and their combinations influence expected support, providing insights into each candidate's chances across different regions and polling conditions. This approach models support rates rather than direct winning probabilities, allowing for a nuanced prediction that reflects variations by candidate, state, and recency.

Our model predicts that Donald Trump will win by a narrow margin, with an average support of 44.51% compared to Kamala Harris's 43.86%. Trump leads in six out of seven key swing states, suggesting that this localized support could enhance his overall chances despite only a slight national lead. Among the predictor variables analyzed, state and recency are the most significant indicators of support trends, reflecting the "winner-takes-all" nature of the U.S. electoral system and the increasing accuracy of polling data as Election Day approaches.

The remainder of this paper is structured as follows: [@sec-data] provides an overview of the dataset, details of the parameters, outcome and predictor variables, and the packages used during processing. [@sec-model] explains the modeling approach, and best model selection, justifying the choice of predictors and outlining the methods used to forecast the price change of banana and strawberry flavored products. [@sec-results] presents the findings, including a summary of the predicted price change for each flavored products, and figures demonstrate the price change distribuion across month and food categories. In [@sec-discussion], we discuss the implications of these results, the limitations of our analysis, and what can we do next to improve our model. Additional methodological details and diagnostics are included in the appendix.



# Data {#sec-data}

## Overview

In this analysis, we used R [@citeR] to investigate canadian grocery price data. Our dataset, sourced from Jacob Filipp's project hammer [@hammer], provided the change of canadian grocery price from 8 vendors: Voila, T&T, Loblaws, No Frills, Metro, Galleria, Walmart and Save-On-Foods, from February 28, 2024 to November 26, 2024 (when this article was written). We examined factors that might influencing the price of seasonal fruits flavored food, including vendor, rain fall, month and category of the food.

Several R packages were vital for our data manipulation, modeling, and visualization efforts. The dplyr package provided efficient tools for data transformation and summarization [@dplyr], while modelsummary enhanced the presentation of model outputs in a clear and organized manner [@modelsummary]. kableExtra created customizable tables to improve our data presentation [@kableExtra]. Finally, testthat ensured the reliability of our analyses through code testing [@testthat]. Our workflow closely adhered to best practices, as outlined in [@tellingstories], enhancing the robustness of our predictive framework.
--------------------------------------

## Measurement
	

In this section, we describe the process of transforming the raw Canadian grocery price data into a structured dataset for analysis. Since this study focuses on price changes in foods with seasonal fruit flavors, we selected bananas and strawberries as representatives. Bananas were chosen for their popularity in winter, and strawberries for spring. Compared to other seasonal fruits like watermelon and pomegranate, bananas and strawberries have a larger consumer base in Canada, making it easier to collect relevant data for model building.

The original Canadian grocery price data was collected by Jacob Filipp through screen-scraping the website interfaces of eight vendors and compiled into the \textbf{Project Hammer} dataset. This dataset contains two tables: \textbf{Hammer 4 Raw} and \textbf{Hammer 4 Product}.
\textbf{Hammer 4 Raw} includes the scrape time, product name, single-item price, unit price (e.g., price per 100g), past prices, additional information (e.g., availability or discounts), and a unique product ID.
\textbf{Hammer 4 Product} provides detailed information, such as brand, vendor, sales unit, and product detail page links.
Since the data comes from website scraping, it contains many gaps and ambiguities, making cleaning difficult. Details about data collection and cleaning are provided in Appendix A.

We have considered sources like Statistics Canada, the Retail Council of Canada, and Open Data Portals as potential data providers. However, after reviewing their datasets, we found they do not meet the needs of our study. These datasets focus on broad food categories rather than specific flavored products like strawberry or banana. They are also ganeralized on time scale, lacking the specific needed to track monthly price changes or vendor-level details, which are critical for modeling seasonal price changes. Therefore, we determined these sources are unsuitable for our research.

To better analyze price changes for banana and strawberry-flavored foods, we added data from the \textbf{"About Rain Gauge Locations and Precipitation"} dataset from Open Data Toronto []. This dataset includes rain gauge locations across Toronto and recorded precipitation. Rainfall was included as a predictor since consumer demand for seasonal fruits often correlates with weather conditions, such as a preference for watermelon and strawberries during dry summers []. The dataset only uses rainfall data because the original grocery price data lacks sales location details.

This structured dataset enables us to analyze trends in seasonal fruit-flavored food prices over time. The goal is to examine price trends for these foods during in-season and off-season sales and identify key influencing factors.


## Outcome Variables

### Change of Monthly Averaged Price for Banana and Strawberry Flavored Product

[@fig-one] illustrates the monthly average price distribution of banana and strawberry-flavored products. Most products are priced between 0 and 10 dollars, with very few exceeding 10 dollars. This indicates that the majority of sales fall within the lower price range, with prices above 20 dollars being rare. The average price distribution of strawberry and banana-flavored products shows no significant difference, though strawberry products have a slightly smaller proportion in the 0 to 10 dollar range compared to banana products.

```{r}
#| label: fig-one
#| fig-cap: Distribution of Monthly Averaged Price for Banana and Strawberry Flavored Product
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for average price distribution
ggplot(model_data, aes(x = monthly_avg_price)) +
  geom_histogram(aes(y = ..density..),
                 bins = 30,
                 fill = "blue",
                 color = "black",
                 alpha = 0.7
  ) +
  geom_density(color = "black", fill = "salmon", alpha = 0.6) +
  labs(
    x = "Average Price",
    y = "Density"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    strip.text = element_text(size = 12), # Adjust facet label size
    axis.title = element_text(size = 14), # Adjust axis title size
    axis.text = element_text(size = 12)  # Adjust axis label size
  )


```

```{r}
#| label: fig-two
#| fig-cap: Distribution of Monthly Averaged Price Change for Banana and Strawberry Flavored Product from July 2024 to Novermber 2024
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(model_data, aes(x = as.factor(month), y = price_change, color = price_change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )


```

[@fig-two] illustrates the price change of monthly average distribution of banana and strawberry-flavored products. Overall, strawberry-flavored products show greater price fluctuation compared to banana-flavored ones. Banana product prices typically vary within a range of ±1.5 dollars, while strawberry prices fluctuate within ±2.5 dollars. However, neither flavor shows a clear trend of overall price increases or decreases over the months.


This contradicts our hypothesis: we anticipated that banana-flavored product prices might increase between July and November, as bananas are a popular fall and winter flavor, while strawberry-flavored product prices might decline during this period, given their popularity as a summer flavor.


## Predictor Variables

### Summary of Predictor Variables

- **Vendor:** Canada's eight major suppliers include Voila, T&T, Loblaws, No Frills, Metro, Galleria, Walmart, and Save-On-Foods.

- **Average Rainfall Per Month:** Using the precipitation data from the "About Rain Gauge Locations and Precipitation" dataset, we calculated the monthly average rainfall for Toronto from July to November 2024, with measurements in millimeters.

- **Food Category:** We categorized banana and strawberry-flavored foods into five groups: beverage, yogurt, flavored tea, solid snack, and fruit. The "beverage" category includes all drinks except tea and yogurt-based beverages. The "flavored tea" category encompasses both tea drinks and flavored tea bags, while "fruit" refers to various types of strawberry or banana fruit.

- **Month:** Month records the corresponding month information when the price data for each product was collected. In this dataset, it starts from July to November.

### Vendor

Based on [@fig-vendor], we observed that the overall number of strawberry-flavored products is significantly higher than that of banana-flavored products. This is because the original dataset shows that the quantity of strawberry-flavored products is roughly 3-4 times greater than that of banana-flavored products, indicating that strawberry-flavored items have a broader audience. Save-On-Foods has the lowest share in both flavor categories, suggesting that they either offer fewer food types overall or focus on selling other product categories rather than fruit-flavored foods.

```{r}
#| label: fig-vendor
#| fig-cap: Distribution of the Counts of Banana and Strawberry Flavored Food Offered in Each Vendor
#| echo: false
#| warning: false
#| message: false

# Create a bar plot for vendor distribution
ggplot(model_data, aes(x = vendor)) +
  geom_bar(fill = "blue", color = "black", alpha = 0.7) + 
  labs(
    x = "Vendor",
    y = "Count"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels for better readability
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )


```

### Average Rainfall Per Month

[@fig-rain] shows the average monthly rainfall in Toronto, measured in millimeters. It is evident that October had the lowest rainfall, while July had the highest. From July to October, there is a continuous downward trend, with a rebound in November. We chose rainfall as a predictor because it is highly correlated with time and seasonal changes, and we believe it will be helpful in our model.

```{r}
#| label: fig-rain
#| fig-cap: Average Rainfall in Toronto from July 2024 to November 2024
#| echo: false
#| warning: false
#| message: false

# Assuming rain_data is your dataset
ggplot(rain_data, aes(x = as.factor(month), y = avg_rainfall)) +
  geom_bar(stat = "identity", fill = "blue", color = "black", alpha = 0.7) + 
  labs(
    x = "Month",
    y = "Average Rainfall (mm)",
    title = "Average Rainfall per Month"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )


```

### Food Category

In [@fig-category], we can see that solid snacks have the highest overall prices, reaching up to 80 dollars per unit, while flavored tea has the lowest overall prices. Additionally, the price distribution for solid snacks, fruit, and beverages is relatively dispersed, whereas yogurt and flavored tea show more tightly clustered price distributions. We believe this is because flavored tea and yogurt are more specialized categories compared to the others.

```{r}
#| label: fig-category
#| fig-cap: Distribution of Monthly Averaged Price for Banana and Strawberry Flavored Product within Category
#| echo: false
#| warning: false
#| message: false
# Convert pct column to numeric if it is not already

# Create the plot for price distribution by category
ggplot(model_data, aes(x = category, y = monthly_avg_price, color = monthly_avg_price)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Category",
    y = "Average Price"
  ) +
  theme_minimal() +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )


```

### Month

[@fig-month] shows the distribution of the Monthly Averaged Price for Banana and Strawberry Flavored Products over time. It is clear that strawberry-flavored products are priced higher than banana-flavored products in all months. However, neither flavor shows a noticeable increasing or decreasing trend in price distribution across the months.

```{r}
#| label: fig-month
#| fig-cap: Distribution of Monthly Averaged Price for Banana and Strawberry Flavored Product from July 2024 to Novermber 2024
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(model_data, aes(x = as.factor(month), y = monthly_avg_price, color = monthly_avg_price)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price",
    title = "Average Price Distribution by Month"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )

```


# Model {#sec-model}

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

model_linear_1 <-
  readRDS(file = here::here("models/model_linear_1.rds"))

model_linear_2 <-
  readRDS(file = here::here("models/model_linear_2.rds"))

model_linear_3 <-
  readRDS(file = here::here("models/model_linear_3.rds"))

model_linear_4 <-
  readRDS(file = here::here("models/model_linear_4.rds"))

model_linear_5 <-
  readRDS(file = here::here("models/model_linear_5.rds"))


```


The goal of this section is to build a robust predictive model for price changes in banana and strawberry flavored products. The key challenge lies in ensuring the model effectively captures the dynamics of price changes despite limited sample size and temporal coverage. To address this, we evaluated multiple model specifications to identify the one that best aligns with our predictive objectives.

We chose to model the monthly average unit price changes for banana and strawberry flavored products rather than making more precise predictions, such as price per 100g. This decision was driven by the original dataset's limitations, which include a variety of measurement units (e.g., per 100g, per 100ml, per 1L, per 1kg, per lb) and the fact that many products only provide prices for each product without corresponding measurement details. As a result, we focused on unit prices, acknowledging that this might reduce the model's performance.

We incorporated Vendor, Food Category, Average Rainfall, and Month as predictors. Recognizing potential interactions among these variables. For example, rainfall and month are typically strongly correlated, and food category might interact with both month and vendor. We developed a series of linear models for the prediction. By systematically comparing models with different interaction terms, we aimed to identify the best-performing model to deliver reliable predictions.

## Model Set-up

Our goal is to model the price changes of strawberry and banana flavored products based on Vendor, Food Category, Average Rainfall, and Month. The model incorporates interaction terms to capture how combinations of these factors jointly influence price changes, providing a clearer understanding of which factors most significantly affect the pricing of seasonal fruit flavored products.

\
\begin{align*}
\mathrm{Pct}_i = &\ \beta_0 + \beta_1 \cdot \mathrm{Vendor}_i + \beta_2 \cdot \mathrm{Category}_i + \beta_3 \cdot \mathrm{Month}_i + \beta_4 \cdot \mathrm{Average Rainfall}_i \\
& + \beta_5 \cdot (\mathrm{Vendor}_i \times \mathrm{Category}_i) + \beta_6 \cdot (\mathrm{Category}_i \times \mathrm{Month}_i) \\
& + \beta_7 \cdot (\mathrm{Month}_i \times \mathrm{Average Rainfall}_i) + \beta_8 \cdot (\mathrm{Category}_i \times \mathrm{Average Rainfall}_i) + \epsilon_i
\end{align*}
\

Where

-   $y_i$ : The percentage of support for candidate in poll i.
-   $\beta_0$: Intercept term, representing the predicted `Average price of the Product` when all independent variables are 0.
-   $\beta_1$: Main effect of `Vendor`, capturing the influence of the candidate.
-   $\beta_2$: Main effect of `Category`, reflecting the influence of how recent the poll is on `Average price of the Product`.
-   $\beta_3$: Main effect of `Month`, indicating the impact of different states on `Average price of the Product`.
-   $\beta_4$: Main effect of `Average Rainfall`, indicating the impact of different states on `Average price of the Product`.
-   $\beta_5$: Interaction effect between `Vendor` and `Category`, capturing the combined influence of the candidate and state.
-   $\beta_6$: Interaction effect between `Category` and `Month`, reflecting the joint impact of recency and state on `pct`.
-   $\beta_7$: Interaction effect between `Month` and `Average rainfall`, representing the combined influence of the candidate and recency of the poll.
-   $\beta_8$: Interaction effect between `Category` and `Average rainfall`, representing the combined influence of the candidate and recency of the poll.
-   $\epsilon_i$: The error term, assumed to follow a normal distribution with mean 0.

### Model Interpretation

This regression model aims to predict price changes for strawberry and banana flavored products by incorporating both main effects and interaction terms. The intercept represents the baseline price change when all predictors are zero. Main effects include vendor, average rainfall, food category, and month, capturing how each factor independently influences price. For example, as the months progress into winter, strawberry flavored products, often associated with summer, may see a price drop.

To better understand more complex dynamics, the model includes two-way interaction terms, such as vendor and category, category and month, and month and average rainfall. These interactions reveal how factors influence one another. For instance, vendors may focus on specific product types, such as selling more beverages than fruits. The interaction between category and month reflects seasonal preferences, like reduced demand for beverages during Canada’s cold winters. The interaction between rainfall and month highlights their direct relationship, with June being Canada’s wettest month and November its driest.

Finally, the model includes an error term to account for unexplained variability, enhancing its predictive reliability. By combining both individual and interdependent relationships, the model offers a nuanced approach to forecasting price changes for these products.

## Model Justification

```{r}
#| label: tbl-linear
#| tbl-cap: "Predicted Average Supporting Percentages for Donald Trump vs. Kamala Harris by Random Forest"
#| echo: false
#| warning: false
#| message: false

# Extract summary statistics and add variables included in each model
model_summary <- tibble(
  Model = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),
  Variables = c(
    linebreak("Vendor, Category, Month, Average Rainfall"), 
    linebreak("Vendor, Category × Month, Average Rainfall"), 
    linebreak("Vendor, Category, Month × Average Rainfall"),
    linebreak("Vendor, Month, Category × Average Rainfall"),
    linebreak("Vendor × Category, Month, Average Rainfall")
  ),
  `R²` = round(c(summary(model_linear_1)$r.squared, 
                 summary(model_linear_2)$r.squared, 
                 summary(model_linear_3)$r.squared,
                 summary(model_linear_4)$r.squared,
                 summary(model_linear_5)$r.squared), 5),
  `Adjusted R²` = round(c(summary(model_linear_1)$adj.r.squared,
                          summary(model_linear_2)$adj.r.squared, 
                          summary(model_linear_3)$adj.r.squared,
                          summary(model_linear_4)$adj.r.squared,
                          summary(model_linear_5)$adj.r.squared), 5),
  `AIC` = round(c(AIC(model_linear_1), AIC(model_linear_2), AIC(model_linear_3), AIC(model_linear_4), AIC(model_linear_5)), 5),
  `BIC` = round(c(BIC(model_linear_1), BIC(model_linear_2), BIC(model_linear_3), BIC(model_linear_4), BIC(model_linear_5)), 5),
  `RMSE` = round(c(sqrt(mean(residuals(model_linear_1)^2)), 
                   sqrt(mean(residuals(model_linear_2)^2)), 
                   sqrt(mean(residuals(model_linear_3)^2)),
                   sqrt(mean(residuals(model_linear_4)^2)),
                   sqrt(mean(residuals(model_linear_5)^2))), 5)
)

# Display the table using kable
model_summary %>%
  kable(digits = 4, escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(2, width = "8em")


```



[@tbl-linear] summarizes the performance metrics for five models, each with different interactions, while the first model contains no interaction.

Model 1, which includes basic predictors (Vendor, Category, Month, and Average Rainfall), exhibits poor predictive performance with an R² of 0.0038 and an RMSE of 0.50983, indicating limited explanatory power. Model 2 improves slightly by incorporating an interaction between Category and Month, increasing R² to 0.00890 and lowering RMSE to 0.5085, suggesting minor gains in prediction accuracy. Model 3, which includes an interaction between Month and Average Rainfall, yields no improvement over Model 1, with identical R² (0.00383) and RMSE (0.5098), highlighting the limited value of this interaction.

Model 4 adds an interaction between Category and Average Rainfall, resulting in a marginally higher R² of 0.0043 but with negligible impact on RMSE (0.5097). Finally, Model 5 introduces an interaction between Vendor and Category, leading to an R² of 0.00821 and an RMSE of 0.5087, showing slight improvement but still limited overall explanatory power.

In conclusion, none of the models provide strong predictive accuracy, but Model 2 achieves the best balance among them with the highest R² (0.0089) and lowest RMSE (0.50853). However, the overall low R² values indicate that these predictors and interactions capture only a small portion of the variation in price changes.

## Optimization

```{r}

tree_data <- model_data

tree_data$month_category <- with(tree_data, interaction(month, category))

interaction_terms <- model.matrix(~month * category - 1, data=tree_data)
tree_data <- cbind(tree_data, interaction_terms)
main_effects <- tree_data[c("vendor", "avg_rainfall")]
X <- cbind(main_effects, interaction_terms)
y <- tree_data$price_change

set.seed(333)
trainIndex <- createDataPartition(y, p = 0.8, list = FALSE)
train_data <- X[trainIndex,]
test_data <- X[-trainIndex,]
train_y <- y[trainIndex]
test_y <- y[-trainIndex]

tuneGrid <- expand.grid(mtry = c(2, 5, 10))

set.seed(333)
rf_model <- train(
  x = train_data,
  y = train_y,
  method = "rf",
  tuneGrid = tuneGrid,
  trControl = trainControl(method = "cv", number = 10),
  metric = "RMSE",
  ntree = 200
)

```

```{r}
#| label: tbl-rfsum
#| echo: false
#| warning: false
#| message: false

# Extract RMSE and other metrics from the model
model_metrics <- tibble(
  Metric = c("RMSE", "Number of Trees", "Best mtry"),
  Value = c(
    min(rf_model$results$RMSE),  # Minimum RMSE from cross-validation
    rf_model$finalModel$ntree,  # Number of trees used
    rf_model$bestTune$mtry      # Best mtry value selected
  )
)

# Display the model metrics table
model_metrics %>%
  kable(digits = 4, escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" " = 1, "Model Evaluation Metrics" = 1)) %>%
  column_spec(1, bold = TRUE, width = "12em")

# Extract variable importance
var_importance <- varImp(rf_model, scale = TRUE)

# Convert to tibble for display
importance_table <- as_tibble(var_importance$importance, rownames = "Variable") %>%
  arrange(desc(Overall)) %>%  # Sort by importance
  mutate(Overall = round(Overall, 2))  # Round importance scores

# Summing up rows for month6 to month11
month_sum <- importance_table %>%
  filter(grepl("^month[6-9]|month1[01]$", Variable)) %>% # Select month6 to month11
  summarise(Overall = sum(Overall)) %>%                # Sum their importance
  mutate(Variable = "month")                           # Add the new row label

# Removing rows for month6 to month11 and adding the summarized row
importance_table_transformed <- importance_table %>%
  filter(!grepl("^month[6-9]|month1[01]$", Variable)) %>% # Remove month6 to month11 rows
  bind_rows(month_sum)                                    # Add the new row


# Summing up rows for categoryFruit, categorySolid, and categoryYogurt
category_sum <- importance_table_transformed %>%
  filter(Variable %in% c("categoryFruit", "categorySolid", "categoryYogurt")) %>% # Select relevant rows
  summarise(Overall = sum(Overall)) %>%                                         # Sum their importance
  mutate(Variable = "category")                                                 # Add the new row label

# Removing rows for categoryFruit, categorySolid, and categoryYogurt
# Adding the summarized row
importance_table_transformed_2 <- importance_table_transformed %>%
  filter(!Variable %in% c("categoryFruit", "categorySolid", "categoryYogurt")) %>% # Remove old rows
  bind_rows(category_sum) 


# Summing up rows for all remaining variables (excluding Category, month, vendor, avg_rainfall)
month_category_sum <- importance_table_transformed_2  %>%
  filter(!Variable %in% c("category", "month", "vendor", "avg_rainfall")) %>% # Select remaining rows
  summarise(Overall = sum(Overall)) %>%                                       # Sum their importance
  mutate(Variable = "month:category")                                         # Add the new row label

# Removing old rows and adding the new row
final_importance_table <- importance_table_transformed_2  %>%
  filter(Variable %in% c("category", "month", "vendor", "avg_rainfall")) %>% # Keep important rows
  bind_rows(month_category_sum)                                              # Add the new summarized row

# Arrange the table for better readability
final_importance_table <- final_importance_table %>%
  arrange(desc(Overall))

# Rename avg_rainfall to average rainfall
final_importance_table <- final_importance_table %>%
  mutate(Variable = ifelse(Variable == "avg_rainfall", "average rainfall", Variable))


# Display variable importance table
final_importance_table  %>%
  kable(digits = 2, escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" " = 1, "Variable Importance" = 1)) %>%
  column_spec(1, bold = TRUE, width = "12em")


```

Due to the limitations of linear models in handling interaction terms, we propose an optimized model—Random Forest. The consistently poor performance of linear models suggests that a linear relationship may not adequately explain the price changes of banana and strawberry flavored products in relation to the predictors. We chose Random Forest because our data includes interaction terms, and linear analysis is not suitable for such data. Random Forest excels at handling interactions and nonlinear relationships, as it can automatically identify and leverage these complex interactions through its decision tree structure without the need for manual adjustments. In contrast, linear models have limited capacity to handle interactions, requiring manual specification, and are less effective at capturing nonlinear effects.

[@tbl-rfsum] presents the prediction results obtained using the Random Forest model.

Compared to the best performing Linear Model 2, the Random Forest model demonstrates higher predictive accuracy. Model 2, which includes basic predictors (Vendor, Category, Month, and Average Rainfall) along with an interaction between Category and Month, achieves an RMSE of 0.50853, indicating limited improvement in prediction accuracy. On the other hand, the Random Forest model, with 200 trees, achieves an RMSE of 0.5076, showcasing a slight reduction in error and an overall better fit to the data.

The Random Forest model further outperforms the linear model in handling complex relationships and interactions. By incorporating important variables such as Vendor, Month, Month:Category, and Average Rainfall, and automatically detecting complex interactions between predictors, the Random Forest model demonstrates its ability to account for these factors effectively. Notably, the model's variable importance analysis reveals that 'Vendor' has the most significant impact on predictions, followed by 'Month' and 'Month:Category', highlighting the model’s capacity to prioritize key features. In conclusion, the Random Forest model provides stronger predictive power and better captures the underlying complexities of the data, surpassing the linear model in performance.



# Result {#sec-results}


```{r}
#| label: tbl-resultone
#| tbl-cap: "Summary Statistics of Predicted Change in Average Price of Strawberry and Banana Flavored Product by Linear Model Two"
#| message: false
#| echo: false
#| warning: false

# Step 1: Predict price changes for the existing dataset
predict_data_lm <- model_data %>%
  mutate(Predicted_Price_Change = predict(model_linear_2, newdata = model_data))

# Step 2: Filter the dataset for 'strawberry' and 'banana' flavor products
flavor_data <- predict_data_lm %>%
  filter(flavor %in% c("strawberry", "banana"))

# Step 3: Calculate average predicted price change for each flavor across the dataset
flavor_summary <- flavor_data %>%
  group_by(flavor) %>%
  summarise(
    Avg_Price_Change = mean(Predicted_Price_Change, na.rm = TRUE),
    Median_Price_Change = median(Predicted_Price_Change, na.rm = TRUE),
    Min_Price_Change = min(Predicted_Price_Change, na.rm = TRUE),
    Max_Price_Change = max(Predicted_Price_Change, na.rm = TRUE),
    SD_Price_Change = sd(Predicted_Price_Change, na.rm = TRUE),
    Total_Products = n()
  )

# Step 4: Present the summary using kable
flavor_summary %>%
  kable(
    col.names = c("Flavor", "Avg Change", "Median Change", "Min Change", "Max Change", "SD of Change", "Sample Size"),
    digits = 4,
    booktabs = TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down"))



```

[@tbl-resultone] summarizes the price change statistics for banana and strawberry flavored products predicted by linear model two.

Banana flavored products have an average price change of 0.0091, with a median change of 0.0181 across 1,376 products. Strawberry-flavored products show a slightly higher average change of 0.0100, with a median of 0.0207. For both of the flavors, their price changes  range from -0.109 to 0.1125. However, for banana flavored product, their sample size is roughly only a quarter of strawberry product sample size.Overall, strawberry-flavored products exhibit slightly higher average price changes and more variation compared to banana-flavored products.

```{r}
#| label: tbl-resulttwo
#| tbl-cap: "Summary Statistics of Predicted Change in Average Price of Strawberry and Banana Flavored Product by Random Forest"
#| echo: false
#| warning: false
#| message: false


tree_data <- tree_data[, !duplicated(names(tree_data))]

tree_data <- tree_data %>%
  mutate(PredictedPriceChange = predict(rf_model, newdata = tree_data))

results <- tree_data %>%
  group_by(flavor) %>%
  summarise(AveragePredictedPriceChange = mean(PredictedPriceChange))

total_change <- sum(results$AveragePredictedPriceChange)

results %>%
  kable(
    col.names = c("Flavor", "Average Predicted Price Change"),
    digits = 4,
    booktabs = TRUE
  ) %>%
  kable_styling(latex_options = c("striped", "scale_down"))

```

[@tbl-resulttwo] summarizes the price change statistics for banana and strawberry flavored products predicted by random forest model.

Banana flavored products have an average price change of 0.0085, while strawberry flavored products show a slightly higher average change of 0.0103. This result means that for random forest estimation, the price of both banana and strawberry flavored products are gonna increase, but only by very little scale.


```{r}
#| label: fig-lmone
#| fig-cap: Distribution of Linear Model Two Predicted Monthly Price Changes for Banana and Strawberry Products by Month  
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(predict_data_lm, aes(x = as.factor(month), y = Predicted_Price_Change, color = Predicted_Price_Change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price") +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  ) 

```

[fig-lmone] illustrates the predicted monthly price changes for strawberry and banana-flavored products. The price trends show no significant differences between the two flavors, with nearly stable prices in July, a slight dip in August, and minor increases in October and November. October saw the highest increase, while August experienced the largest decrease. However, the average price changes remained within ±0.1 units, indicating limited fluctuation.

```{r}
#| label: fig-lmtwo
#| fig-cap: Distribution of Linear Model Two Predicted Monthly Price Changes for Banana and Strawberry Products by Category
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Create the plot for price distribution by month
ggplot(predict_data_lm, aes(x = category, y = Predicted_Price_Change, color = Predicted_Price_Change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Food Category",
    y = "Average Price"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels
  )

```
[fig-lmtwo], like [fig-lmone], uses predictions from Linear Model 2. However, while [fig-lmone] shows predicted price changes across months, [fig-lmtwo] presents their distribution across food categories. Similar to the monthly distribution, there is no significant difference between strawberry and banana-flavored products across categories, except for flavored tea. Banana-flavored tea shows a downward price trend with fewer products compared to strawberry-flavored tea, which exhibits rising prices. For beverage, fruit, and solid snack categories, both flavors demonstrate increasing price trends, while yogurt prices remain largely stable.

```{r}
#| label: fig-rfone
#| fig-cap: Distribution of Random Forest Model Predicted Monthly Price Changes for Banana and Strawberry Products by Month
#| echo: false
#| eval: true
#| warning: false
#| message: false

predict_data_rf <- model_data %>%
  mutate(predicted_price_change = predict(model_rf, newdata = model_data))

# Create the plot for price distribution by month
ggplot(predict_data_rf, aes(x = as.factor(month), y = predicted_price_change, color = predicted_price_change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price") +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12)
  )


```

To address the limitations of the linear model, we also generated predictions using the random forest model, as shown in [@fig-rfone] and [@fig-rftwo].

[@fig-rfone] illustrates the predicted price changes for banana and strawberry-flavored products across months. While the differences are not pronounced, there are notable variations in their distributions. In July, August, and September, prices for both flavors decline, with banana-flavored products experiencing a steeper drop. By October, prices for both flavors rise, with a sharper increase for banana-flavored products. In November, price increases continue but at a slower pace, with some products, particularly banana-flavored ones, showing significant price reductions. Overall, the price changes largely fall within a range of ±0.1 units.

```{r}
#| label: fig-rftwo
#| fig-cap: This figure shows the distribution of monthly price changes for banana and strawberry products. A higher concentration around zero indicates more stable prices, while wider distributions suggest greater variability.
#| echo: false
#| eval: true
#| warning: false
#| message: false

predict_data_rf <- model_data %>%
  mutate(predicted_price_change = predict(model_rf, newdata = model_data))

# Create the plot for price distribution by month
ggplot(predict_data_rf, aes(x = category, y = predicted_price_change, color = predicted_price_change)) +
  geom_violin(fill = "blue", alpha = 0.4) +  # Use violin plot to show the distribution of the average prices
  geom_jitter(width = 0.1, alpha = 0.7) +  # Scatter plot for individual data points, jittered for visibility
  scale_color_gradient(low = "blue", high = "red") +  # Color gradient based on the price
  labs(
    x = "Month",
    y = "Average Price",
    title = "Average Price Distribution by Month"
  ) +
  theme_minimal() +
  facet_wrap(~flavor) +
  theme(
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    strip.text = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels
  )


```

[@fig-rftwo] presents the predicted price changes for banana and strawberry-flavored products across food categories. Notable differences emerge in their distribution across categories. Prices for beverages, fruit, and solid snacks show an overall increase, while yogurt remains relatively stable. For flavored tea, banana-flavored products exhibit minimal price changes, whereas strawberry-flavored products see a noticeable price increase. Interestingly, some banana-flavored products show significantly larger price increases compared to their strawberry counterparts, resulting in a more dispersed price distribution for banana-flavored items.

# Discussion {#sec-discussion}

## Summery of Findings

In our study, we analyzed the price changes of banana and strawberry-flavored products using both linear and Random Forest models. The linear model showed an average price change of 0.0091 for banana-flavored products and 0.0100 for strawberry-flavored products. The Random Forest model yielded similar results, with banana-flavored products averaging a price change of 0.0085, slightly lower than strawberry-flavored products at 0.0103. Both models indicated small price increases from July to November, with some differences in the distribution of price changes. July remained stable, while August and September saw slight declines. October and November experienced small increases, with the largest rise in October. Overall, price changes for both flavors stayed within ±0.1 units. Across food categories, beverages, fruits, and solid snacks showed price increases, while yogurt remained stable. Only in the flavored tea category did we observe a difference: banana-flavored products decreased, while strawberry-flavored ones increased. Overall, both models showed similar trends, with banana and strawberry products experiencing slight price increases, and strawberry-flavored products seeing a slightly higher increase.


This result surprised us, as our initial hypothesis assumed bananas to be more popular in winter and strawberries in summer. However, the model predicts that the price of strawberry-flavored products will increase more than that of banana-flavored ones. This suggests that while seasonal fruits may be more popular during their peak seasons, it does not necessarily mean their flavored products are less favored in off-seasons. For example, during winter, people might be even more inclined to purchase strawberry-flavored products to enjoy the taste of strawberries, rather than opting for banana-flavored ones.

Among all predictors, vendor and month are the most influential, while food category and average rainfall have relatively limited impact. Interestingly, the interaction between month and food category is the second most important predictor after month. We believe the dominance of vendor is due to the unique sales strategies each vendor employs, such as deciding which products to sell and how to adjust prices across different periods and categories. This makes vendor the most significant contributor to price changes, as vendors directly control pricing. The next most important predictors are month and its interaction with category, which reflects seasonal variations in consumer behavior and preferences for different food types. The interaction term provides deeper insights into these temporal consumption patterns. Although food category and average rainfall contribute less, both have importance values exceeding 20, demonstrating their limited but indispensable role in the model.

## Limitation

The model's subpar performance highlights a major limitation of this study: the quality of the original dataset, which significantly impacted the model's accuracy.

First, while data collection from vendor websites began on February 28, 2024, as noted by the dataset's creator, only a small number of products were captured until July 10, when large-scale scraping commenced. Unfortunately, strawberry- and banana-flavored products were not included in the earlier data. The earliest recorded prices for these products appear on June 11, leaving nearly four months of missing data. This substantial gap reduced both the dataset's size and its temporal coverage, making predictions more challenging.

Second, the dataset's diversity in product categories and inconsistent labeling across vendors resulted in significant data heterogeneity. For example, units of measurement were not standardized. Ideally, predictions should have been based on consistent units, such as price per 100g of bananas or per 100ml of strawberry beverages. However, some products were only listed with unit prices, while others had inconsistent units—for instance, yogurt prices were listed per 100g, per 100ml, or per box. This forced us to rely on unit prices, a less precise approach. For example, a 300ml beverage and a 2L beverage may have vastly different prices, but their per-100ml prices could be similar.

Third, the dataset had an uneven distribution of products between the two flavors. Strawberry-flavored products, likely due to their broader popularity or insufficient representation of banana-flavored products in the dataset, were far more prevalent. This resulted in denser data distributions for strawberry products compared to bananas, potentially introducing bias in banana product predictions. In some categories, such as flavored tea, the number of banana-flavored products was particularly sparse, further exacerbating prediction biases.

Lastly, our assumptions may not align with real-world dynamics. We hypothesized that seasonal fruits would see higher demand and prices during their peak seasons, with lower off-season demand. However, this may only hold for the fruits themselves and not their flavored products, which could be influenced by more significant factors than seasonality. Off-season sales, for instance, might not lead to price decreases but rather increases, as higher prices might offset lower demand. Overall, food price changes are influenced by numerous factors, making this a highly complex and nuanced subject. We underestimated the challenges of modeling price dynamics accurately.

## Future Study

Future research should address the limitations identified in this study to enhance the accuracy of modeling price changes for seasonal fruit-flavored products. First, improved data collection methods are essential. Future efforts should ensure consistent and comprehensive data coverage for all target product categories and flavors from the initial scraping period, ideally spanning 2–3 years to improve reliability. Second, standardizing product measurement units is crucial for enhancing prediction accuracy. Converting prices to uniform units, such as per 100 grams or per 100 milliliters, would reduce data heterogeneity and enable more meaningful comparisons. Efforts should also be made to unify units within the same food category and to resolve inconsistencies through manual data supplementation or improved web-scraping methods. For example, fruit prices could be collected uniformly per 100 grams, while beverages could be standardized per 100 milliliters. Products lacking detailed unit information, such as “boxed fruits” or “a case of strawberry juice,” could be supplemented with manual research or advanced scraping techniques. Lastly, incorporating additional predictive factors such as regional variations, promotional activities, or consumer preferences could provide deeper insights into the drivers of price changes. Leveraging these improvements, future studies could develop more robust models to better understand and forecast the dynamics of seasonal fruit-flavored product prices.

To build on the existing work with linear models and Random Forest, future studies could explore alternative machine learning algorithms that might better capture the complexities of flavored product price dynamics. Gradient Boosting Machines (GBMs), such as XGBoost or LightGBM, could be particularly effective, as they excel in handling structured data and capturing non-linear relationships while minimizing overfitting. Similarly, Support Vector Machines (SVMs) could be applied, especially if the focus shifts to classification tasks, such as identifying the likelihood of price increases or decreases based on features like flavor and category.


\newpage

# Appendix a. {-}

## Overview of Emerson College Polling Methodology (October 23-25, 2024)

The Emerson College Polling conducted a survey from October 23 to 25, 2024, targeting 1,000 likely voters to investigate the differences in support for various candidates. In this presidential election, 58% support former President Donald Trump, while 39% support Vice President Kamala Harris.

## Population, Frame, and Sample

In this context, the target population consists of likely voters in the U.S. elections, defined by their likelihood to vote in the upcoming elections and their voting history, both of which are self-reported in the survey. The sampling frame specifically focuses on likely voters in Montana, who were reached through a combination of cell phone contacts provided by Aristotle and an online voter panel from CINT. The sample consists of 1,000 likely voters randomly selected from the sampling frame, with their status determined by a combination of voter history, registration status, and demographic data, all of which are self-reported. This methodology provides a balanced overview of Montana voters' priorities, with a credibility interval of +/- 3%.

## Sampling Approach and Trade-offs

Emerson College utilized a mixed-mode sampling approach for its poll of likely voters in Montana. This strategy involved two main methods: sending MMS text messages linked to an online survey using Aristotle’s voter lists and accessing a pre-screened, opt-in online panel from CINT. The MMS method is efficient and cost-effective, allowing participants to complete the survey at their convenience, which can enhance response rates. The online panel broadens coverage to include voters not reachable through text, capturing a wider demographic range across the state. Together, these methods create a diverse sample while reducing costs compared to traditional phone or in-person interviews.

However, this approach has trade-offs. The MMS survey requires recipients to have active cell phones and internet, potentially excluding older or less tech-savvy voters. Additionally, the online panel consists of self-selected participants, which may not fully reflect the general voter population. Mixing data from both sources can introduce inconsistencies, as each method may attract different respondent types, necessitating careful weighting to maintain balance and accuracy. Smaller demographic subsets, such as age, race, or education, carry higher credibility intervals due to reduced sample sizes, limiting precision in analysis. Overall, the mixed approach optimizes reach, reduces costs, and shows the priority needs of Montana’s voters, although there are limitations.

## Non-response Handling

Emerson College does not provide specific details regarding its non-response management. While it mentions that data were weighted by demographics such as gender, education, race, age, party registration, and region to align with the 2024 likely voter model, this weighting primarily addresses demographic imbalances and does not directly mitigate non-response bias. The survey lacks information on common non-response strategies, such as follow-up attempts, participation incentives, or specific adjustments for non-responders. This absence raises concerns about potential non-response bias, particularly if certain demographic groups were less likely to engage with the survey.

## Questionnaire Design

This questionnaire has strong points. Its straightforward and clear wording makes questions easy for respondents to follow and reduces potential confusion. By focusing on issues like the economy, housing, and voter approval for specific candidates, it captures key voter concerns in Montana, offering a concise view. The use of multiple questions around candidate approval, voter issues, and demographics adds depth to the questionnaire.
However, the questionnaire also has limitations. While demographic questions enhance the survey’s representativeness, smaller groups (e.g., nonbinary individuals) may carry higher credibility intervals, reducing precision for those subgroups. The mixed-mode approach (online panel and mobile) improves access but still risks non-response bias, as certain demographics might be less likely to participate. Overall, the design achieves clarity and breadth, though response biases and sample variations should be considered in interpreting the findings. For example, in this survey of 1,000 Montana voters, only 5 respondents identified as nonbinary or other genders. Since statistical reliability depends on the number of responses, small groups have higher variability, meaning their responses can swing widely due to each individual answer carrying greater weight.

# Appendix b. {-}

## Idealized Methodology for Forecasting the U.S. Presidential Election

We aim to develop a methodology for forecasting U.S. presidential election outcomes by conducting a survey with a $100,000 budget. Using stratified random sampling and multi-mode recruitment, the survey targets 10,000 likely voters across demographic and regional lines. Key measures include data validation checks, weighted analysis, and predictive modeling to ensure accuracy. Results will be enriched by aggregating reputable data sources like FiveThirtyEight for a better forecast.

## Budget Allocation

Funding allocations will focus on ensuring thorough and effective sampling, recruitment, data validation, and analysis methods are employed with a total budget of no more than $10,000. The proposed budget breakdown is as follows:

Survey platform costs: $10,000 (subscription fees for online survey tools such as Google Forms or Qualtrics)

Respondent incentives: $10,000 (gift cards or other incentives to encourage participation)

Recruitment and staffing: $35,000 (staffing costs for survey distribution and data collection)

Data analysis tools: $20,000 (statistical software licenses, data cleaning and analysis)

Marketing and promotion: $10,000 (awareness and engagement campaigns)

Contingency fund: $5,000 (for unexpected expenses)

## Sampling Approach

The sampling approach will employ a stratified random sampling method to ensure representation across various demographic groups, including age, gender, race, education level, geographical location, and party affiliation. The target population consists of likely voters in the U.S., defined by historical voting behavior and self-reported intentions to vote. A sample size of approximately 10,000 respondents will be aimed at ensuring statistical robustness and a credibility interval of +/- 1% at a 95% confidence level.
This will be achieved through a combination of national voter registration databases to identify potential respondents. For example, we can utilize the National Voter Registration Act (NVRA) data from the National Association of Secretaries of State (NASS) to access information on registered voters. This database will allow us to filter for likely voters based on their registration status and historical voting behavior, ensuring that our sampling frame is representative of the electorate. By using reliable sources, we can create a sampling framework that enhances the accuracy of our election forecasts.

## Respondent Recruitment and Data Validation

To reach the target population, a multi-mode recruitment strategy will be implemented:
Online Surveys: Use Google Forms to distribute the survey electronically.
Telephone Surveys: Conduct live telephone interviews to capture demographics that might not engage online.
Text Messaging Surveys: Implement SMS surveys to reach younger demographics and those without regular internet access.
Incentives: Offer gift cards or other small incentives for participation, particularly for online respondents. This can enhance response rates and engagement.

To effectively reach our target population and capture a diverse range of perspectives, we will implement a multi-mode recruitment strategy tailored to different demographic groups and communication preferences. This approach includes online surveys using a Google Forms questionnaire, which will be widely distributed through social media, email lists, and community networks to maximize reach among individuals who frequently engage online. The user-friendly platform allows participants to complete the survey quickly and anonymously on any internet-enabled device. The survey can be accessed through the following link: [https://forms.gle/oSbad52Vuw9Z9Wf46](https://forms.gle/oSbad52Vuw9Z9Wf46). Additionally, we will conduct live telephone interviews to include participants who may not be reachable through online channels, ensuring we capture responses from populations that might otherwise be underrepresented. To further engage younger demographics and individuals with limited internet access, we will implement SMS-based surveys, allowing participants to respond quickly via text. To encourage participation and improve response rates, small incentives such as digital gift cards will be offered, particularly for online respondents, with details communicated at the survey's start and awarded upon completion to ensure transparency. This comprehensive approach will enable us to gather a robust and representative dataset, providing valuable insights into the preferences and priorities of voters across multiple demographics.

## Poll Aggregation and Modeling

Poll results will be aggregated using statistical methods to identify trends and analyze historical voting patterns. For model building, we will implement a weighted analysis to ensure demographic representation, applying specific weights based on factors such as age, gender, race, and education level, as well as state significance to reflect regional variations in voter behavior. Predictive analytics will primarily involve logistic regression to model voting preferences and forecast election outcomes, supplemented by time-series analysis to track changes in voter sentiment over the campaign period. To enhance our findings, we will combine our data with reputable sources like FiveThirtyEight, utilizing their aggregation techniques to enrich our analysis. 

\newpage

# References

